{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPXOOpSBsD3C58QJDSdiqHO"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Statistical Analysis of ERP Data\n",
        "\n",
        "In the previous lesson we visualized the difference waveform plot.<br>\n",
        "Based on this plot, we can infer a significant difference between experimental conditions (Violation–Control).\n",
        "\n",
        "In the present lesson, we will proceed to the statistical analysis of ERP data in order to check whether the Violation–Control difference is statistically significant.\n",
        "\n",
        "For this purpose, we will perform a **one-sample t-test** and compute a **p-value**.\n",
        "\n",
        "A one-sample t-test statistically determines if the mean of a single sample significantly differs from a known or hypothesized population mean (a specific constant value).\n",
        "\n",
        "The p-value indicates the probability that the observed result will occur if the null hypothesis is true.\n",
        "\n",
        "The null hypothesis assumes that there is no difference between two or more groups with respect to a characteristic.\n",
        "\n",
        "We test if the observed difference is due to chance or a real effect, by checking if the p-value is below a chosen significance level (e.g., 0.05):\n",
        "* a small p-value (e.g., < 0.05) suggests a statistically significant difference, meaning you reject the null hypothesis\n",
        "* a large p-value (e.g., > 0.05) means you fail to reject it, indicating the observed difference could be due to chance."
      ],
      "metadata": {
        "id": "QNv7erbHkiEy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install MNE Library"
      ],
      "metadata": {
        "id": "RgtvdhrImaOe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# install MNE library\n",
        "!pip install -q mne"
      ],
      "metadata": {
        "id": "fQccTOlMmST5"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download Data Files\n",
        "\n",
        "The present study involves 26 data files.<br>\n",
        "The list of the locations of these files is stored in a text file named `sentence_n400_files_list.txt`.\n",
        "\n",
        "First, we download this text file, and then we download the data files using the `wget` utility."
      ],
      "metadata": {
        "id": "uTrO1EJoorpm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "2h2Gzh68mhc0"
      },
      "outputs": [],
      "source": [
        "# download text file containing the list of data files\n",
        "!wget -q https://datascience.faseela.ma/wp-content/uploads/data-science/sentence_n400_files_list.txt\n",
        "\n",
        "# download data files\n",
        "!wget -q -i https://datascience.faseela.ma/wp-content/uploads/data-science/sentence_n400_files_list.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Libraries\n",
        "\n",
        "### SciPy library\n",
        "\n",
        "t-test is implemented in the SciPy library.\n",
        "\n",
        "We will use the **`scipy.stats`** module from SciPy."
      ],
      "metadata": {
        "id": "7zCtD6xKmg2D"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RdZDyUyvlaFp"
      },
      "outputs": [],
      "source": [
        "import mne\n",
        "mne.set_log_level('error')\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import glob\n",
        "\n",
        "from scipy import stats"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define Parameters\n",
        "\n",
        "We define a list of experimental conditions."
      ],
      "metadata": {
        "id": "WPxipJWiTdjG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define experimental conditions\n",
        "conditions = ['Control', 'Violation']"
      ],
      "metadata": {
        "id": "R6iGDMU7TnGp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set a List of the Data Files\n",
        "\n",
        "We use the Python **`glob`** module which allows to find pathnames matching a specified pattern, and returns a list of path names matching that pattern."
      ],
      "metadata": {
        "id": "TA2CMoUTUXwl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create a list of the data files\n",
        "data_files = glob.glob('sentence_n400_p*-ave.fif' )\n",
        "\n",
        "# print list of the data files\n",
        "data_files"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R6MT2F7dUj31",
        "outputId": "a006cab4-2749-49d1-ac40-23fda8f3d55d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['sentence_n400_p12-ave.fif',\n",
              " 'sentence_n400_p01-ave.fif',\n",
              " 'sentence_n400_p22-ave.fif',\n",
              " 'sentence_n400_p13-ave.fif',\n",
              " 'sentence_n400_p10-ave.fif',\n",
              " 'sentence_n400_p02-ave.fif',\n",
              " 'sentence_n400_p17-ave.fif',\n",
              " 'sentence_n400_p23-ave.fif',\n",
              " 'sentence_n400_p24-ave.fif',\n",
              " 'sentence_n400_p09-ave.fif',\n",
              " 'sentence_n400_p06-ave.fif',\n",
              " 'sentence_n400_p04-ave.fif',\n",
              " 'sentence_n400_p14-ave.fif',\n",
              " 'sentence_n400_p25-ave.fif',\n",
              " 'sentence_n400_p03-ave.fif',\n",
              " 'sentence_n400_p08-ave.fif',\n",
              " 'sentence_n400_p07-ave.fif',\n",
              " 'sentence_n400_p20-ave.fif',\n",
              " 'sentence_n400_p18-ave.fif',\n",
              " 'sentence_n400_p26-ave.fif',\n",
              " 'sentence_n400_p21-ave.fif',\n",
              " 'sentence_n400_p19-ave.fif',\n",
              " 'sentence_n400_p15-ave.fif',\n",
              " 'sentence_n400_p16-ave.fif',\n",
              " 'sentence_n400_p05-ave.fif',\n",
              " 'sentence_n400_p11-ave.fif']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Read the Data Files\n",
        "\n",
        "We store the data files as a dictionary, where:\n",
        "* each key is a condition label,\n",
        "* each value is a list of **`Evoked`** objects (the data from that condition, with each participant’s **`Evoked`** object as a list item).\n",
        "\n",
        "We use the **`enumerate()`** function to loop over conditions and build our dictionary of **`Evoked`** objects.\n",
        "\n",
        "We use the index from the **`enumerate()`** function to specify which condition (list item) we read from each participant’s data file.\n",
        "\n",
        "We use list comprehension to build the list of **`Evoked`** objects for each condition."
      ],
      "metadata": {
        "id": "gnXAw1u3WC2M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create dictionary for Evoked objects\n",
        "evokeds = {}\n",
        "\n",
        "for idx, c in enumerate(conditions):\n",
        "    evokeds[c] = [mne.read_evokeds(d)[idx].set_montage('easycap-M1') for d in data_files]"
      ],
      "metadata": {
        "id": "3zmRGiUIWHWn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Difference Waveforms\n",
        "\n",
        "We create difference waveforms to more easily visualize the difference between conditions, and compare it to zero (i.e., no difference between conditions).\n",
        "\n",
        "In order to get CIs that reflect the variance across participants, we need to compute the Violation-Control difference separately for each participant.\n",
        "\n",
        "We use the **`mne.combine_evoked()`** function which merges multiple **`Evoked`** data objects by calculating their weighted sum.\n",
        "\n",
        "We set the values of weights as `1` for Violation and `-1` for Control.\n",
        "\n",
        "We put this function in a list comprehension to loop over participants."
      ],
      "metadata": {
        "id": "oPrv0R7bbWl0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create a list of difference waveform\n",
        "diff_waves = [mne.combine_evoked([evokeds['Violation'][subj],\n",
        "                                  evokeds['Control'][subj]\n",
        "                                 ],\n",
        "                                 weights=[1, -1]\n",
        "                                 )\n",
        "              for subj in range(len(data_files))\n",
        "              ]"
      ],
      "metadata": {
        "id": "1-Ee49IHb_Rd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## t-test\n",
        "\n",
        "To test whether an ERP effect is significant we perform a one-sample t-test between a pair of conditions, on the ERP data averaged over a time period of interest and at one or a few electrodes.\n",
        "\n",
        "In the present study, we predicted an N400, which we knew from previous studies with similar stimuli would likely be largest between 400–600 ms, at midline channels Cz, CPz, and Pz.\n",
        "\n",
        "We will use the **`scipy.stats.ttest_1samp()`** function from SciPy’s stats module to perform a one-sample t-test.\n",
        "\n",
        "We use as input the Violation-Control differences for each participant (**`diff_waves`**), since if they are significantly different from zero, that will be evidence for a difference in amplitude between these two conditions.\n",
        "\n",
        "We first compute the average over the 400–600 ms time window, for each participant, at the channels of interest, and store these in a NumPy array on which we then perform the t-test.\n",
        "\n",
        "The rows in the array correspond to participants, and the columns to channels.\n",
        "\n",
        "To create this Numpy array, we perform the following steps:\n",
        "\n",
        "* **Step 1:** We define the time window and channels of interest as variables.<br>\n",
        "We use tuples to indicate that we would not want these values changed after they’re defined.\n",
        "\n",
        "* **Step 2:** We create a list named **`evoked_data_list`**.<br>\n",
        "Each item in this list is a 2D Numpy array with shape (number of channels, number of time points).<br>\n",
        "This array stores the data of an **`Evoked`** object.<br>\n",
        "We create this list as follows:\n",
        "   * We use a list comprehension to loop through the items in the list **`diff_waves`**. Each item is an **`Evoked`** object.\n",
        "   * We use the **`evoked.get_data()`** method to extract data from the **`Evoked`** object.<br>\n",
        "   This method returns data as 2D Numpy array with shape (number of channels, number of time points).\n",
        "   * We set some keywords arguments of the **`evoked.get_dat()`** method:\n",
        "      * We use the **`picks`** keyword argument to specify which electrode(s) we want. Here we pass the **`roi tuple`**.\n",
        "      * We use the **`tmin`** and **`tmax`** keywords arguments to specify the time range over which we want to extract the ERP data. This is the tuple **`time_win`**.\n",
        "   * Result: each item in the list is a 2D Numpy array storing evoked data of a participant.\n",
        "\n",
        "* **Step 3:** We create a list named **`evoked_mean_list`**.<br>\n",
        "Each item in the list is a 1D Numpy array with shape (number of channels).<br> Each element in the array is the mean of a channel.<br>\n",
        "We create this list as follows:\n",
        "   * We use a list comprehension to loop through the items in the list **`evoked_data_list`**. Each item is a Numpy array.\n",
        "   * We use the **`np.mean()`** function to compute the average of each column in the Numpy array.<br>\n",
        "   We set the **`axis=1`** keyword argument to instructs the function to average over columns (axis 1 corresponds to time points) and not rows (axis 0 corresponds to electrodes).\n",
        "\n",
        "* **Step 4:**  We create a Numpy array named **`y`** from the list **`evoked_mean_list`**, using the **`np.array()`** function, which converts the list to a 2D Numpy array with 26 rows (participants) and 3 columns (channels)."
      ],
      "metadata": {
        "id": "s5bkeMNt2EYk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set time window\n",
        "time_win = (.400, .600)\n",
        "\n",
        "# set region of interest\n",
        "roi = ('Cz', 'CPz', 'Pz')\n",
        "\n",
        "# create a list in which each item is a 2D numpy array storing\n",
        "# a participant evoked data stored in diff_waves list\n",
        "evoked_data_list = [item.get_data(picks=roi,\n",
        "                               tmin=time_win[0],\n",
        "                               tmax=time_win[1]\n",
        "                               )\n",
        "                   for item in diff_waves\n",
        "                   ]\n",
        "\n",
        "# create a list in which each item is a 1D numpy array\n",
        "# each element in this array is the mean of columns of\n",
        "# the numpy array which is an item in the list evoked_data_list\n",
        "evoked_mean_list = [np.mean(item, axis=1) for item in evoked_data_list]\n",
        "\n",
        "# create a 2D numpy array from the list evoked_mean_list\n",
        "sample_data = np.array(evoked_mean_list)\n",
        "\n",
        "# check shape of result\n",
        "sample_data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o95e9etlH3P_",
        "outputId": "8b90d4b6-7233-42b8-da18-e5404b0f3a27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(26, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note:** in the code above, we have unpacked the steps so one can understand the process.<br>\n",
        "We can pack this code as follows:"
      ],
      "metadata": {
        "id": "qKSsvmsRIYVt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_data = np.array([np.mean(e.get_data(picks=roi,\n",
        "                                 tmin=time_win[0],\n",
        "                                 tmax=time_win[1]\n",
        "                                 ),\n",
        "                      axis=1)\n",
        "              for e in diff_waves\n",
        "              ]\n",
        "             )"
      ],
      "metadata": {
        "id": "pvKM09ZPF-ZP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Perform the t-test\n",
        "\n",
        "We use the **`scipy.stats.ttest_1samp()`** function which performs a one-sample t-test to determine if the mean of a sample is statistically different from a given population mean.\n",
        "\n",
        "It returns the calculated **t-statistic** and the **p-value**.\n",
        "\n",
        "It produces NumPy arrays for its outputs which here we assign to variables we name **`t_statistic`** and **`p_value`**.\n",
        "\n",
        "As this function returns arrays, we print the first element of each array.\n",
        "\n",
        "We call this function with two arguments as **`ttest_1samp(a, popmean)`**:\n",
        "* **`a`**: array_like, sample observations.\n",
        "* **`popmean`**: float, expected value (mean) under the null hypothesis."
      ],
      "metadata": {
        "id": "PAV4mPp9u0Nx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set expected value (mean) under the null hypothesis\n",
        "null_hypothesis_mean = 0\n",
        "\n",
        "# perform t-test\n",
        "t_statistic, p_value = stats.ttest_1samp(sample_data, null_hypothesis_mean)\n",
        "\n",
        "# print results\n",
        "print('t-statistic = ', str(round(t_statistic[0], 2)))\n",
        "print('p-value = ', str(round(p_value[0], 4)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mtwPRddgyHB4",
        "outputId": "b7d897c2-eb03-4d3f-c482-2028fb0a02ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "t-statistic =  -3.23\n",
            "p-value =  0.0035\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The p-value is lower than 0.05, so we can reject the null hypothesis of no difference between the conditions, and conclude that the difference between conditions is statistically significant."
      ],
      "metadata": {
        "id": "pPb-86yXDAbd"
      }
    }
  ]
}